LLM_PROVIDER=gemini

GEMINI_API_KEY='your-apikey'
GEMINI_MODEL=gemini-1.5-flash

# Ollama Configuration (if using Ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# LLM Generation Settings
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1000
